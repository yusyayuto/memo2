#!/bin/bash
# SecurityHub 全件確実取得スクリプト（セッション切れ対策版）

echo "🚀 SecurityHub全件取得（確実版）開始"
echo "======================================"

# nohupバックグラウンド実行用スクリプト作成
cat > full_export_background.sh << 'EOF'
#!/bin/bash
# バックグラウンド実行用内部スクリプト

# ログファイル設定
PROGRESS_LOG="progress.log"
ERROR_LOG="error.log"
JSON_OUTPUT="complete_findings.json"
CSV_OUTPUT="complete_findings.csv"
TEMP_FILE="temp_batch.json"

# ログ初期化
echo "=== SecurityHub全件取得開始: $(date) ===" > "$PROGRESS_LOG"
echo "=== エラーログ: $(date) ===" > "$ERROR_LOG"

# 処理開始
echo "[]" > "$JSON_OUTPUT"
NEXT_TOKEN=""
BATCH_COUNT=0
TOTAL_FINDINGS=0
ERROR_COUNT=0

echo "$(date): 全件取得処理開始" >> "$PROGRESS_LOG"

while true; do
    BATCH_COUNT=$((BATCH_COUNT + 1))
    echo "$(date): バッチ ${BATCH_COUNT} 取得開始..." >> "$PROGRESS_LOG"
    
    # API呼び出し（エラーハンドリング強化）
    if [ -z "$NEXT_TOKEN" ]; then
        # 初回
        if ! aws securityhub get-findings --max-items 100 --output json > "$TEMP_FILE" 2>>"$ERROR_LOG"; then
            echo "$(date): API呼び出しエラー（バッチ ${BATCH_COUNT}）" >> "$PROGRESS_LOG"
            ERROR_COUNT=$((ERROR_COUNT + 1))
            if [ $ERROR_COUNT -gt 3 ]; then
                echo "$(date): 連続エラー制限に達しました。処理終了。" >> "$PROGRESS_LOG"
                break
            fi
            echo "$(date): 30秒待機後リトライ..." >> "$PROGRESS_LOG"
            sleep 30
            continue
        fi
    else
        # 2回目以降
        if ! aws securityhub get-findings --max-items 100 --starting-token "$NEXT_TOKEN" --output json > "$TEMP_FILE" 2>>"$ERROR_LOG"; then
            echo "$(date): API呼び出しエラー（バッチ ${BATCH_COUNT}）" >> "$PROGRESS_LOG"
            ERROR_COUNT=$((ERROR_COUNT + 1))
            if [ $ERROR_COUNT -gt 3 ]; then
                echo "$(date): 連続エラー制限に達しました。処理終了。" >> "$PROGRESS_LOG"
                break
            fi
            echo "$(date): 30秒待機後リトライ..." >> "$PROGRESS_LOG"
            sleep 30
            continue
        fi
    fi
    
    # 成功時はエラーカウントリセット
    ERROR_COUNT=0
    
    # 取得件数確認
    if ! CURRENT_COUNT=$(jq '.Findings | length' "$TEMP_FILE" 2>/dev/null); then
        echo "$(date): JSON解析エラー（バッチ ${BATCH_COUNT}）" >> "$PROGRESS_LOG"
        continue
    fi
    
    TOTAL_FINDINGS=$((TOTAL_FINDINGS + CURRENT_COUNT))
    echo "$(date): ${CURRENT_COUNT}件取得 (累計: ${TOTAL_FINDINGS}件)" >> "$PROGRESS_LOG"
    
    # データ結合
    if ! jq -s '.[0] + .[1].Findings' "$JSON_OUTPUT" "$TEMP_FILE" > temp_combined.json 2>>"$ERROR_LOG"; then
        echo "$(date): データ結合エラー（バッチ ${BATCH_COUNT}）" >> "$PROGRESS_LOG"
        continue
    fi
    mv temp_combined.json "$JSON_OUTPUT"
    
    # NextToken確認
    NEXT_TOKEN=$(jq -r '.NextToken // empty' "$TEMP_FILE" 2>/dev/null)
    
    if [ -z "$NEXT_TOKEN" ]; then
        echo "$(date): 全データ取得完了！総件数: ${TOTAL_FINDINGS}" >> "$PROGRESS_LOG"
        break
    fi
    
    echo "$(date): 次のバッチに進行（Token: ${NEXT_TOKEN:0:20}...)" >> "$PROGRESS_LOG"
    
    # API制限対策（進捗報告も兼ねる）
    sleep 2
    
    # 進捗報告（10バッチごと）
    if [ $((BATCH_COUNT % 10)) -eq 0 ]; then
        echo "$(date): ===== 進捗報告: ${BATCH_COUNT}バッチ完了、累計${TOTAL_FINDINGS}件 =====" >> "$PROGRESS_LOG"
    fi
done

# CSV変換
echo "$(date): CSV変換開始..." >> "$PROGRESS_LOG"

# CSVヘッダー
cat > "$CSV_OUTPUT" << 'CSVHEADER'
Id,Title,Severity,ComplianceStatus,WorkflowStatus,CreatedAt,UpdatedAt,AwsAccountId,Region,ResourceType,ResourceId,GeneratorId,Confidence,Description,FirstObservedAt,LastObservedAt
CSVHEADER

# JSON→CSV変換（エラーハンドリング付き）
if jq -r '.[] | [
    (.Id // ""),
    ((.Title // "") | gsub("\n"; " ") | gsub(","; ";")),
    (.Severity.Label // ""),
    (.Compliance.Status // ""),
    (.Workflow.Status // ""),
    (.CreatedAt // ""),
    (.UpdatedAt // ""),
    (.AwsAccountId // ""),
    (.Region // ""),
    ((.Resources[0].Type // "") | tostring),
    ((.Resources[0].Id // "") | tostring),
    (.GeneratorId // ""),
    (.Confidence // ""),
    ((.Description // "") | gsub("\n"; " ") | gsub(","; ";") | gsub("\""; "\"\"")),
    (.FirstObservedAt // ""),
    (.LastObservedAt // "")
] | @csv' "$JSON_OUTPUT" >> "$CSV_OUTPUT" 2>>"$ERROR_LOG"; then
    CSV_LINES=$(wc -l < "$CSV_OUTPUT")
    DATA_LINES=$((CSV_LINES - 1))
    echo "$(date): CSV変換完了！データ行数: ${DATA_LINES}" >> "$PROGRESS_LOG"
else
    echo "$(date): CSV変換エラー" >> "$PROGRESS_LOG"
fi

# 最終統計
echo "$(date): ===== 処理完了 =====" >> "$PROGRESS_LOG"
echo "$(date): 総バッチ数: ${BATCH_COUNT}" >> "$PROGRESS_LOG"
echo "$(date): 総取得件数: ${TOTAL_FINDINGS}" >> "$PROGRESS_LOG"
echo "$(date): JSONファイル: ${JSON_OUTPUT}" >> "$PROGRESS_LOG"
echo "$(date): CSVファイル: ${CSV_OUTPUT}" >> "$PROGRESS_LOG"

# ファイルサイズ
if [ -f "$CSV_OUTPUT" ]; then
    CSV_SIZE=$(ls -lh "$CSV_OUTPUT" | awk '{print $5}')
    echo "$(date): CSVサイズ: ${CSV_SIZE}" >> "$PROGRESS_LOG"
fi

# クリーンアップ
rm -f "$TEMP_FILE" temp_combined.json

echo "$(date): 全件取得処理終了" >> "$PROGRESS_LOG"
EOF

# 実行権限付与
chmod +x full_export_background.sh

echo "✅ バックグラウンド実行スクリプト準備完了"
echo ""

# 実行選択
echo "🎯 実行方法を選択してください："
echo ""
echo "方法1: nohupバックグラウンド実行（推奨）"
echo "  - セッション切れても継続"
echo "  - 進捗はログファイルで確認"
echo "  - 最も確実"
echo ""
echo "方法2: 通常実行"
echo "  - リアルタイム進捗表示"
echo "  - セッション切れリスクあり"
echo ""

read -p "方法1(nohup)で実行しますか？ (Y/n): " -n 1 -r
echo

if [[ $REPLY =~ ^[Nn]$ ]]; then
    echo "🔄 通常実行モード"
    ./full_export_background.sh
else
    echo "🚀 nohupバックグラウンド実行開始"
    
    # nohup実行
    nohup ./full_export_background.sh > nohup.out 2>&1 &
    NOHUP_PID=$!
    
    echo "✅ バックグラウンド実行開始完了"
    echo "📊 プロセスID: $NOHUP_PID"
    echo ""
    echo "📋 進捗確認コマンド："
    echo "  tail -f progress.log     # リアルタイム進捗"
    echo "  tail nohup.out          # 実行ログ"
    echo "  ps aux | grep aws       # プロセス確認"
    echo ""
    echo "⏱️  予想完了時間: 15-20分程度"
    echo "🎯 完了確認: ls -la complete_findings.csv"
    echo ""
    echo "🔍 今すぐ進捗確認："
    sleep 3
    tail -f progress.log
fi
